# ğŸŒ Iran Crisis Monitor

Real-time monitoring dashboard that aggregates live news from 7 major international sources and presents events on an interactive dark-themed map with a live news feed.

![Python 3.11](https://img.shields.io/badge/Python-3.11-blue)
![Streamlit](https://img.shields.io/badge/Streamlit-1.30+-red)
![License: MIT](https://img.shields.io/badge/License-MIT-green)

## âœ¨ Features

- **Interactive dark-themed map** â€“ powered by Folium with CartoDB Dark Matter tiles
- **7 live news sources** â€“ Al Jazeera, Reuters, NBC News, Washington Post, CNN, AP News, Liveuamap
- **Colour-coded markers** â€“ airstrikes (red), missiles (purple), explosions (orange), alerts (yellow), military (blue)
- **Live news feed** â€“ scrollable panel with source badges, severity indicators, and relative timestamps
- **Auto-refresh** â€“ fetches new data every ~60 seconds
- **Responsive design** â€“ works on desktop and mobile browsers
- **Modular architecture** â€“ easily add new sources or extend processing

## ğŸš€ Quick Start

### Prerequisites

- **Python 3.11.9** (recommended)
- `pip` package manager

### Installation

```bash
# 1. Clone the repository
git clone <your-repo-url>
cd iran-war-monitoring

# 2. Create and activate virtual environment
py -3.11 -m venv venv
venv\Scripts\activate        # Windows
# source venv/bin/activate   # macOS / Linux

# 3. Install dependencies
pip install -r requirements.txt

# 4. Run the app
streamlit run app.py
```

The app will open at **<http://localhost:8501>**.

## ğŸ—ï¸ Project Structure

```
iran-war-monitoring/
â”œâ”€â”€ app.py                    # Streamlit entry point
â”œâ”€â”€ requirements.txt          # Python dependencies
â”œâ”€â”€ README.md                 # This file
â”œâ”€â”€ .streamlit/config.toml    # Streamlit theme & server config
â”‚
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ settings.py           # Source registry, timing, map defaults
â”‚   â””â”€â”€ locations.py          # ~120 curated Middle East locations
â”‚
â”œâ”€â”€ models/
â”‚   â””â”€â”€ events.py             # NewsEvent model + EventStore
â”‚
â”œâ”€â”€ scrapers/
â”‚   â”œâ”€â”€ base.py               # Abstract scraper with HTTP retry & caching
â”‚   â”œâ”€â”€ aljazeera.py          # Al Jazeera live blog
â”‚   â”œâ”€â”€ apnews.py             # AP News live updates
â”‚   â”œâ”€â”€ reuters.py            # Reuters live
â”‚   â”œâ”€â”€ nbcnews.py            # NBC News live blog
â”‚   â”œâ”€â”€ washpost.py           # Washington Post live updates
â”‚   â”œâ”€â”€ cnn.py                # CNN live updates
â”‚   â””â”€â”€ liveuamap.py          # Liveuamap (API + HTML fallback)
â”‚
â”œâ”€â”€ processing/
â”‚   â”œâ”€â”€ geocoder.py           # Location extraction from text
â”‚   â”œâ”€â”€ categorizer.py        # Event type classification
â”‚   â””â”€â”€ deduplicator.py       # Cross-source deduplication
â”‚
â”œâ”€â”€ ui/
â”‚   â”œâ”€â”€ map_component.py      # Folium map builder
â”‚   â”œâ”€â”€ news_feed.py          # News feed HTML renderer
â”‚   â””â”€â”€ styles.py             # Custom CSS (dark theme, responsive)
â”‚
â””â”€â”€ utils/
    â”œâ”€â”€ cache.py              # TTL response cache
    â””â”€â”€ logger.py             # Logging setup
```

## â˜ï¸ Deploy to Streamlit Community Cloud

1. Push this repository to GitHub
2. Go to [share.streamlit.io](https://share.streamlit.io)
3. Connect your GitHub account and select this repository
4. Set:
   - **Main file path**: `app.py`
   - **Python version**: `3.11`
5. Click **Deploy**

No secrets or environment variables are required.

## ğŸ”§ Configuration

Edit `config/settings.py` to change:

| Setting | Default | Description |
|---------|---------|-------------|
| `REFRESH_INTERVAL_SECONDS` | `60` | How often to fetch new data |
| `REQUEST_TIMEOUT_SECONDS` | `15` | HTTP timeout per source |
| `MAX_NEWS_FEED_ITEMS` | `100` | Max events in the feed panel |
| `EVENT_RECENT_MINUTES` | `10` | Highlight events newer than this |
| `MAP_DEFAULT_ZOOM` | `5` | Initial map zoom level |

## â• Adding a New Source

1. Create `scrapers/mysource.py` extending `BaseScraper`
2. Implement the `parse(html)` method
3. Add a `SourceConfig` entry in `config/settings.py`
4. Import and register in `scrapers/__init__.py`

## â• Adding a New Location

Edit `config/locations.py` and add an entry:

```python
"new city": (latitude, longitude),
```

The geocoder will automatically detect this name in news text.

## ğŸ“„ License

MIT â€“ see individual source copyrights for news content.
